#!/usr/bin/env python3
"""
ë°ì´í„°ì…‹ ëª©ë¡ì„ ìë™ìœ¼ë¡œ ìŠ¤ìº”í•´ì„œ JSON íŒŒì¼ë¡œ ìƒì„±í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
"""

import os
import json
from pathlib import Path
from datetime import datetime

def scan_datasets():
    """data í´ë”ë¥¼ ìŠ¤ìº”í•´ì„œ ìœ íš¨í•œ ë°ì´í„°ì…‹ ëª©ë¡ ë°˜í™˜"""
    
    current_dir = Path(__file__).parent.parent
    data_dir = current_dir / 'data'
    
    print(f"ğŸ” Scanning datasets in: {data_dir}")
    
    if not data_dir.exists():
        print(f"âŒ Data directory not found: {data_dir}")
        return []
    
    datasets = []
    
    try:
        # data í´ë” ë‚´ì˜ ëª¨ë“  í´ë” ê²€ì‚¬
        for item in data_dir.iterdir():
            if item.is_dir():
                dataset_name = item.name
                entities_file = item / 'kv_store_full_entities.json'
                relations_file = item / 'kv_store_full_relations.json'
                
                if entities_file.exists() and relations_file.exists():
                    datasets.append(dataset_name)
                    print(f"âœ… Valid dataset found: {dataset_name}")
                else:
                    print(f"âš ï¸ Invalid dataset (missing files): {dataset_name}")
        
        return sorted(datasets)
        
    except Exception as e:
        print(f"âŒ Error scanning datasets: {e}")
        return []

def generate_datasets_json():
    """ë°ì´í„°ì…‹ ì •ë³´ë¥¼ JSON íŒŒì¼ë¡œ ìƒì„±"""
    
    datasets = scan_datasets()
    
    datasets_info = {
        "datasets": datasets,
        "default": datasets[0] if datasets else None,
        "generated": datetime.now().isoformat(),
        "total": len(datasets)
    }
    
    # ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
    current_dir = Path(__file__).parent.parent
    output_file = current_dir / 'src' / 'datasets.json'
    
    # src ë””ë ‰í† ë¦¬ ìƒì„± (ì—†ìœ¼ë©´)
    output_file.parent.mkdir(parents=True, exist_ok=True)
    
    # JSON íŒŒì¼ ìƒì„±
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(datasets_info, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ“„ Generated datasets file: {output_file}")
    print(f"ğŸ“Š Found datasets: {datasets}")
    print(f"ğŸ¯ Default dataset: {datasets_info['default']}")
    
    # dist í´ë”ì—ë„ ë³µì‚¬ (ë¹Œë“œëœ ì•±ì—ì„œ ì‚¬ìš©)
    dist_file = current_dir / 'dist' / 'datasets.json'
    if dist_file.parent.exists():
        with open(dist_file, 'w', encoding='utf-8') as f:
            json.dump(datasets_info, f, ensure_ascii=False, indent=2)
        print(f"ğŸ“„ Copied to dist: {dist_file}")
    
    return datasets_info

if __name__ == "__main__":
    print("ğŸš€ Dataset Scanner ì‹œì‘!")
    print("=" * 50)
    
    result = generate_datasets_json()
    
    if result['total'] > 0:
        print(f"\nğŸ‰ {result['total']}ê°œ ë°ì´í„°ì…‹ ë°œê²¬!")
        print(f"ğŸ“‹ ëª©ë¡: {', '.join(result['datasets'])}")
    else:
        print("\nâŒ ìœ íš¨í•œ ë°ì´í„°ì…‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("ğŸ’¡ data í´ë”ì— ê° ë°ì´í„°ì…‹ë³„ë¡œ ë‹¤ìŒ íŒŒì¼ë“¤ì´ í•„ìš”í•©ë‹ˆë‹¤:")
        print("   â€¢ kv_store_full_entities.json")
        print("   â€¢ kv_store_full_relations.json")
