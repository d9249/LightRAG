# 엔티티 및 관계 추출

<cite>
**이 문서에서 참조된 파일**  
- [operate.py](file://lightrag/operate.py)
- [prompt.py](file://lightrag/prompt.py)
</cite>

## 목차
1. [엔티티 및 관계 추출 개요](#엔티티-및-관계-추출-개요)
2. [추출 프로세스의 핵심 구성 요소](#추출-프로세스의-핵심-구성-요소)
3. [LLM 기반 엔티티 추출 메커니즘](#llm-기반-엔티티-추출-메커니즘)
4. [데이터 검증 및 정규화 프로세스](#데이터-검증-및-정규화-프로세스)
5. [캐싱 및 다중 추출 시도 메커니즘](#캐싱-및-다중-추출-시도-메커니즘)
6. [프롬프트 템플릿 구조](#프롬프트-템플릿-구조)
7. [추출 결과 파싱 로직](#추출-결과-파싱-로직)

## 엔티티 및 관계 추출 개요

LightRAG 시스템은 비정형 텍스트에서 의미 있는 정보를 구조화된 지식 그래프로 변환하는 핵심 기능으로 엔티티 및 관계 추출을 수행합니다. 이 프로세스는 대규모 언어 모델(LLM)을 활용하여 텍스트 청크 내에서 엔티티와 그들 간의 관계를 식별하고, 이를 검증 및 정규화하여 일관성 있는 지식 그래프 데이터로 변환합니다. 이 문서는 `extract_entities` 함수를 중심으로 한 전체 추출 프로세스의 아키텍처와 작동 원리를 상세히 설명합니다.

**Section sources**
- [operate.py](file://lightrag/operate.py#L1674-L1914)

## 추출 프로세스의 핵심 구성 요소

엔티티 및 관계 추출 프로세스는 여러 핵심 구성 요소로 이루어져 있으며, 각각은 특정한 책임을 가집니다. 주요 구성 요소는 다음과 같습니다:

- **`extract_entities`**: 추출 프로세스의 주 진입점으로, 모든 청크에 대해 병렬로 추출 작업을 조정합니다.
- **`_handle_single_entity_extraction`**: 단일 엔티티 추출 결과를 검증하고 정규화하는 함수입니다.
- **`_handle_single_relationship_extraction`**: 단일 관계 추출 결과를 검증하고 정규화하는 함수입니다.
- **`_parse_extraction_result`**: 캐시된 추출 결과를 파싱하여 구조화된 데이터로 변환하는 함수입니다.
- **`PROMPTS['entity_extraction']`**: LLM에 제공되는 엔티티 추출을 위한 프롬프트 템플릿입니다.

이러한 구성 요소들은 상호작용하여 텍스트에서 구조화된 지식을 추출하는 복잡한 워크플로우를 형성합니다.

```mermaid
flowchart TD
A[텍스트 청크] --> B[extract_entities]
B --> C[PROMPTS['entity_extraction']]
C --> D[LLM]
D --> E[추출 결과 문자열]
E --> F[_parse_extraction_result]
F --> G{_handle_single_entity_extraction}
F --> H{_handle_single_relationship_extraction}
G --> I[정규화된 엔티티]
H --> J[정규화된 관계]
I --> K[지식 그래프]
J --> K
```

**Diagram sources**
- [operate.py](file://lightrag/operate.py#L1674-L1914)
- [prompt.py](file://lightrag/prompt.py#L0-L22)

**Section sources**
- [operate.py](file://lightrag/operate.py#L1674-L1914)
- [prompt.py](file://lightrag/prompt.py#L0-L22)

## LLM 기반 엔티티 추출 메커니즘

`extract_entities` 함수는 LLM을 사용하여 각 텍스트 청크에서 엔티티와 관계를 추출하는 핵심 메커니즘을 구현합니다. 이 함수는 비동기적으로 작동하며, 여러 청크를 병렬로 처리할 수 있도록 설계되어 있습니다.

### 초기 추출 단계

함수는 먼저 전역 설정(`global_config`)에서 LLM 모델 함수(`use_llm_func`)와 최대 갈취 횟수(`entity_extract_max_gleaning`)를 가져옵니다. 이후, 각 청크에 대해 다음과 같은 초기 추출을 수행합니다:

1. **프롬프트 구성**: `PROMPTS['entity_extraction']` 템플릿을 사용하여 LLM에 제공할 프롬프트를 생성합니다. 이 프롬프트는 입력 텍스트, 허용되는 엔티티 유형, 예제 등을 포함합니다.
2. **LLM 호출**: 구성된 프롬프트를 LLM에 전달하고, 추출 결과를 문자열 형태로 수신합니다.
3. **결과 처리**: 수신된 결과 문자열은 `_process_extraction_result` 함수를 통해 파싱되어 잠재적인 엔티티와 관계의 목록으로 변환됩니다.

이 초기 추출 단계는 각 청크에 대해 한 번 수행되며, LLM이 텍스트에서 식별할 수 있는 모든 엔티티와 관계를 추출하려고 시도합니다.

### 다중 추출 시도 (Gleaning)

초기 추출 후에도 일부 엔티티나 관계가 누락되었을 가능성을 고려하여, 시스템은 다중 추출 시도(또는 갈취, gleaning) 메커니즘을 제공합니다. 이는 `entity_extract_max_gleaning` 매개변수에 의해 제어되며, 최대 지정된 횟수만큼 추가 추출을 시도합니다.

각 갈취 반복에서 시스템은 다음과 같은 절차를 따릅니다:

1. **계속 추출 프롬프트 사용**: `PROMPTS['entity_continue_extraction']` 프롬프트를 사용하여, 이전에 추출된 내용을 기반으로 누락된 엔티티와 관계를 찾도록 LLM에 요청합니다.
2. **이전 대화 기록 유지**: 초기 추출과 갈취 추출 사이의 대화 기록(`history`)을 유지하여, LLM이 이전에 추출한 내용을 인식하고 중복을 피할 수 있도록 합니다.
3. **결과 병합**: 갈취를 통해 얻은 새로운 엔티티와 관계는 기존 결과에 병합됩니다. 단, 이름이 새로운 엔티티와 관계만 추가되며, 중복은 허용하지 않습니다.
4. **반복 여부 결정**: `PROMPTS['entity_if_loop_extraction']` 프롬프트를 사용하여, LLM이 더 이상 추출할 내용이 있는지("yes") 여부를 판단합니다. "yes"가 아닌 경우 반복을 종료합니다.

이러한 다중 추출 시도는 추출의 포괄성을 높이는 데 중요한 역할을 합니다.

**Section sources**
- [operate.py](file://lightrag/operate.py#L1674-L1914)

## 데이터 검증 및 정규화 프로세스

LLM으로부터 수신된 원시 추출 결과는 형식 오류, 인코딩 문제, 불필요한 문자 등을 포함할 수 있으므로, 신뢰할 수 있는 지식 그래프를 구축하기 위해 철저한 검증과 정규화 과정이 필요합니다. 이 과정은 `_handle_single_entity_extraction` 및 `_handle_single_relationship_extraction` 함수에 의해 수행됩니다.

### 엔티티 검증 및 정규화 (`_handle_single_entity_extraction`)

이 함수는 단일 엔티티 추출 결과를 처리하며, 다음과 같은 단계를 거칩니다:

1. **기본 유효성 검사**: 입력된 속성 리스트의 길이가 4 이상인지, 그리고 첫 번째 요소에 `"entity"` 문자열이 포함되어 있는지 확인합니다.
2. **인코딩 정제**: `sanitize_text_for_encoding` 함수를 사용하여 엔티티 이름, 유형, 설명에 대해 엄격한 UTF-8 인코딩 정제를 수행합니다.
3. **문자 제거**: `clean_str` 함수를 사용하여 HTML 태그, 제어 문자, 불필요한 공백 등을 제거합니다.
4. **비즈니스 로직 정규화**: `normalize_extracted_info` 함수를 사용하여 엔티티 이름과 설명에 대해 도메인 특화된 정규화를 수행합니다.
5. **최종 검증**: 정제 및 정규화 후 엔티티 이름과 설명이 비어 있지 않은지 확인합니다. 비어 있는 경우 경고를 기록하고 `None`을 반환하여 이 엔티티를 무시합니다.

이러한 체계적인 파이프라인을 통해 엔티티 데이터의 품질과 일관성을 보장합니다.

### 관계 검증 및 정규화 (`_handle_single_relationship_extraction`)

관계 추출 결과의 검증 및 정규화도 유사한 파이프라인을 따르지만, 추가적인 검사가 포함됩니다:

1. **기본 유효성 검사**: 속성 리스트의 길이가 5 이상인지, `"relationship"` 문자열이 포함되어 있는지 확인합니다.
2. **소스 및 타겟 엔티티 정제**: 소스 엔티티와 타겟 엔티티에 대해 동일한 인코딩 정제, 문자 제거, 정규화 과정을 적용합니다.
3. **유효성 검사**: 정제 후 소스와 타겟 엔티티 이름이 비어 있지 않은지 확인합니다.
4. **자기 참조 검사**: 소스 엔티티와 타겟 엔티티가 동일한지 확인하고, 동일한 경우 관계를 무시합니다.
5. **관계 속성 처리**: 관계 설명과 키워드를 정제하고, 관계 강도(`weight`)를 부동 소수점 숫자로 파싱합니다. 파싱에 실패하면 기본값 1.0을 사용합니다.

이러한 검증 절차는 지식 그래프의 무결성을 유지하는 데 필수적입니다.

**Section sources**
- [operate.py](file://lightrag/operate.py#L313-L375)
- [operate.py](file://lightrag/operate.py#L378-L456)

## 캐싱 및 다중 추출 시도 메커니즘

시스템의 성능과 효율성을 높이기 위해, 엔티티 추출 프로세스는 캐싱 메커니즘과 다중 추출 시도를 통합합니다.

### 캐싱 메커니즘 (`enable_llm_cache_for_entity_extract`)

`llm_response_cache` 매개변수를 통해 캐싱이 활성화되면, 시스템은 다음과 같은 방식으로 캐시를 활용합니다:

1. **LLM 응답 캐싱**: `use_llm_func_with_cache` 함수를 호출하여, 동일한 프롬프트에 대한 LLM의 응답을 캐시에 저장하거나 기존 캐시된 응답을 재사용합니다. 이는 동일한 텍스트 청크에 대해 반복적인 LLM 호출을 방지하여 비용과 시간을 절약합니다.
2. **청크별 캐시 참조 관리**: 각 텍스트 청크는 `llm_cache_list`라는 필드를 가지며, 이 필드는 해당 청크의 추출에 사용된 캐시 항목들의 키를 저장합니다. `_process_single_content` 함수 내에서 `cache_keys_collector`를 사용하여 이 캐시 키들을 수집하고, 추출이 완료되면 `update_chunk_cache_list` 함수를 통해 청크의 `llm_cache_list`를 일괄적으로 업데이트합니다.

이 캐싱 메커니즘은 `enable_llm_cache_for_entity_extract` 설정이 활성화된 경우에만 작동하며, 시스템의 전반적인 처리 속도를 크게 향상시킵니다.

### 다중 추출 시도 (`entity_extract_max_gleaning`)

`entity_extract_max_gleaning` 매개변수는 LLM이 초기 추출 후 추가로 시도할 수 있는 갈취 횟수의 최대값을 정의합니다. 이 값은 전역 설정에서 가져오며, 시스템이 추출의 포괄성을 얼마나 높이려는지를 제어합니다.

- 값이 0이면, 초기 추출만 한 번 수행되고 추가 갈취는 시도되지 않습니다.
- 값이 N(N>0)이면, 최대 N번의 갈취 추출을 시도할 수 있습니다. 각 시도는 `PROMPTS['entity_continue_extraction']` 프롬프트를 사용하며, 이전 추출 결과를 기반으로 누락된 항목을 찾습니다.
- 반복은 `PROMPTS['entity_if_loop_extraction']` 프롬프트의 응답이 "yes"가 아닐 때 조기에 종료될 수 있습니다.

이 메커니즘은 추출의 정밀도와 포괄성 사이의 균형을 맞추는 데 중요한 역할을 합니다.

**Section sources**
- [operate.py](file://lightrag/operate.py#L1674-L1914)

## 프롬프트 템플릿 구조

`PROMPTS['entity_extraction']` 템플릿은 LLM이 엔티티와 관계를 추출하는 데 필요한 모든 지침을 구조화된 형식으로 제공합니다. 이 템플릿은 다음과 같은 핵심 섹션으로 구성됩니다:

### 목표 (Goal)
LLM의 최종 목표를 명확히 정의합니다: 주어진 텍스트 문서에서 지정된 엔티티 유형의 모든 엔티티와 그들 사이의 관계를 식별하는 것입니다. 출력 언어도 `{language}` 변수를 통해 지정됩니다.

### 단계 (Steps)
추출 과정을 명확한 단계로 나누어 LLM이 따라야 할 절차를 안내합니다:
1. **엔티티 식별**: 엔티티 이름, 유형, 설명을 추출하고, 지정된 형식으로 포맷합니다.
2. **관계 식별**: 명확히 관련된 엔티티 쌍을 식별하고, 관계 설명, 키워드, 강도를 추출합니다.
3. **콘텐츠 키워드 식별**: 전체 텍스트의 주요 개념과 주제를 요약하는 고수준 키워드를 식별합니다.
4. **출력 형식**: 모든 식별된 엔티티와 관계를 단일 목록으로 반환하며, `{record_delimiter}`를 목록 구분자로 사용합니다.
5. **완료 표시**: 작업 완료 후 `{completion_delimiter}`를 출력합니다.

### 예제 (Examples)
`PROMPTS['entity_extraction_examples']` 리스트에 정의된 실제 예제를 포함합니다. 이러한 예제는 LLM이 올바른 형식과 내용을 이해하는 데 도움을 주며, 추출의 일관성을 높입니다. 예제는 다양한 도메인(예: 인물, 기술, 조직 등)을 다루며, 실제 출력 형식을 보여줍니다.

### 실제 데이터 (Real Data)
실제 처리할 텍스트가 `{input_text}` 자리표시자에 삽입되어 LLM에 전달됩니다.

이 템플릿 구조는 LLM이 복잡한 추출 작업을 체계적으로 수행할 수 있도록 하며, 출력의 일관성과 예측 가능성을 보장합니다.

**Section sources**
- [prompt.py](file://lightrag/prompt.py#L0-L22)

## 추출 결과 파싱 로직

LLM으로부터 수신된 원시 텍스트 결과는 구조화된 데이터로 변환되어야 합니다. `_parse_extraction_result` 함수는 이 파싱 작업을 담당하며, `extract_entities` 함수 내에서 사용되는 동일한 로직을 재사용합니다.

### 파싱 절차
1. **레코드 분리**: `split_string_by_multi_markers` 함수를 사용하여, 결과 문자열을 `{record_delimiter}` 또는 `{completion_delimiter}`를 기준으로 분리하여 개별 레코드 목록을 생성합니다.
2. **레코드 처리**: 각 레코드에 대해 정규 표현식을 사용하여 괄호 `()` 안의 내용을 추출합니다.
3. **속성 분리**: 추출된 레코드 내에서 `{tuple_delimiter}`를 기준으로 속성들을 분리합니다.
4. **엔티티/관계 판별 및 처리**:
    - `_handle_single_entity_extraction` 함수를 호출하여 엔티티로 파싱을 시도합니다. 성공하면 결과를 `maybe_nodes` 딕셔너리에 추가합니다.
    - 실패하면 `_handle_single_relationship_extraction` 함수를 호출하여 관계로 파싱을 시도합니다. 성공하면 결과를 `maybe_edges` 딕셔너리에 추가합니다.
5. **결과 반환**: 파싱된 엔티티와 관계의 딕셔너리를 튜플 형태로 반환합니다.

이 함수는 특히 캐시된 추출 결과를 다시 로드할 때 중요하며, 시스템이 이전에 수행한 추출 작업의 결과를 일관성 있게 재사용할 수 있도록 합니다.

**Section sources**
- [operate.py](file://lightrag/operate.py#L798-L858)