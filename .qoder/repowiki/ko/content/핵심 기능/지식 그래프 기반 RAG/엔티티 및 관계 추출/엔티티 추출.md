
# 엔티티 추출

<cite>
**이 문서에서 참조된 파일**   
- [operate.py](file://lightrag/operate.py)
- [prompt.py](file://lightrag/prompt.py)
- [constants.py](file://lightrag/constants.py)
- [utils.py](file://lightrag/utils.py)
</cite>

## 목차
1. [소개](#소개)
2. [엔티티 추출 메커니즘 개요](#엔티티-추출-메커니즘-개요)
3. [extract_entities 함수 분석](#extract_entities-함수-분석)
4. [entity_extraction 프롬프트 템플릿](#entity_extraction-프롬프트-템플릿)
5. [DEFAULT_ENTITY_TYPES 상수의 역할](#default_entity_types-상수의-역할)
6. [재시도 메커니즘 분석](#재시도-메커니즘-분석)
7. [_handle_single_entity_extraction 함수 분석](#_handle_single_entity_extraction-함수-분석)
8. [유틸리티 함수의 데이터 품질 보장](#유틸리티-함수의-데이터-품질-보장)
9. [실제 코드 예제를 통한 추출 과정](#실제-코드-예제를-통한-추출-과정)
10. [오류 처리 및 로깅 전략](#오류-처리-및-로깅-전략)
11. [결론](#결론)

## 소개
이 문서는 LightRAG 시스템의 핵심 기능인 엔티티 추출 메커니즘을 심층적으로 분석합니다. 엔티티 추출은 비정형 텍스트에서 의미 있는 정보를 구조화된 형태로 변환하는 과정으로, 지식 그래프 구축의 기초를 형성합니다. 본 문서는 `operate.py`의 `extract_entities` 함수가 어떻게 작동하는지 설명하고, `prompt.py`에 정의된 `entity_extraction` 프롬프트 템플릿의 구조와 역할을 분석합니다. 또한 `DEFAULT_ENTITY_TYPES` 상수가 엔티티 추출에 미치는 영향과, 재시도 메커니즘(`entity_extract_max_gleaning`)이 실패한 추출 시도를 어떻게 처리하는지 설명합니다. `_handle_single_entity_extraction` 함수의 내부 로직을 분석하고, `sanitize_text_for_encoding`과 `clean_str` 같은 유틸리티 함수가 데이터 품질을 어떻게 보장하는지 설명합니다. 실제 코드 예제를 통해 엔티티 이름, 유형, 설명의 추출 및 정규화 과정을 단계별로 보여주며, 오류 처리 및 로깅 전략을 포함합니다.

## 엔티티 추출 메커니즘 개요
LightRAG의 엔티티 추출 메커니즘은 대규모 언어 모델(LLM)을 활용하여 텍스트 청크에서 엔티티와 관계를 추출하는 복잡한 파이프라인입니다. 이 프로세스는 크게 세 단계로 나뉩니다. 첫째, `extract_entities` 함수는 입력된 텍스트 청크를 반복 처리하며, 각 청크에 대해 LLM에 쿼리를 전송합니다. 둘째, LLM은 `entity_extraction` 프롬프트 템플릿에 따라 엔티티와 관계를 구조화된 형식으로 반환합니다. 셋째, 반환된 결과는 `_handle_single_entity_extraction`과 `_handle_single_relationship_extraction` 함수를 통해 파싱되고 정제됩니다. 이 과정은 `entity_extract_max_gleaning` 매개변수에 의해 제어되는 재시도 메커니즘과 결합되어, 초기 추출에서 누락된 정보를 보완합니다. 전체 프로세스는 `DEFAULT_ENTITY_TYPES`와 같은 전역 설정에 의해 조정되며, `sanitize_text_for_encoding`과 `clean_str` 같은 유틸리티 함수를 통해 데이터의 무결성과 일관성을 보장합니다.

## extract_entities 함수 분석
`extract_entities` 함수는 엔티티 추출 파이프라인의 핵심 진입점입니다. 이 함수는 텍스트 청크의 딕셔너리와 전역 설정을 입력으로 받아, 추출된 엔티티와 관계의 목록을 반환합니다. 함수는 먼저 `global_config`에서 `llm_model_func`와 `entity_extract_max_gleaning` 값을 추출합니다. 이후, 사용자 정의 매개변수에서 언어와 엔티티 유형을 가져오며, `DEFAULT_SUMMARY_LANGUAGE`와 `DEFAULT_ENTITY_TYPES`를 기본값으로 사용합니다. 함수는 `PROMPTS["entity_extraction"]` 템플릿을 기반으로 초기 프롬프트를 생성하고, `PROMPTS["entity_continue_extraction"]`과 `PROMPTS["entity_if_loop_extraction"]`을 재시도 프롬프트로 준비합니다. 각 텍스트 청크는 비동기적으로 처리되며, `use_llm_func_with_cache`를 통해 LLM에 쿼리를 전송하고 결과를 캐시합니다. 초기 추출 후, `entity_extract_max_gleaning` 횟수만큼 재시도 루프를 실행하여 누락된 엔티티를 찾습니다. 최종적으로, 모든 청크의 결과는 `merge_nodes_and_edges` 함수로 전달되어 지식 그래프에 통합됩니다.

**Section sources**
- [operate.py](file://lightrag/operate.py#L1674-L1914)

## entity_extraction 프롬프트 템플릿
`entity_extraction` 프롬프트 템플릿은 LLM이 엔티티와 관계를 추출하는 데 사용하는 지침의 핵심입니다. 이 템플릿은 다음과 같은 구조를 가집니다. 첫째, 목표(Goal) 섹션은 주어진 텍스트에서 지정된 유형의 엔티티와 그들 사이의 관계를 식별하라는 명확한 지시를 포함합니다. 둘째, 단계(Steps) 섹션은 추출 프로세스를 세부적으로 정의합니다. 1단계에서는 엔티티를 식별하고, 각 엔티티에 대해 `entity_name`, `entity_type`, `entity_description`을 추출하도록 지시합니다. 2단계에서는 식별된 엔티티 간의 관계를 찾고, `source_entity`, `target_entity`, `relationship_description`, `relationship_strength`, `relationship_keywords`를 추출합니다. 3단계에서는 전체 텍스트의 주요 개념을 요약하는 `content_keywords`를 추출합니다. 마지막으로, 출력 형식(Output) 섹션은 결과를 `record_delimiter`로 구분된 단일 목록으로 반환하고, `completion_delimiter`로 종료하라는 형식 지침을 제공합니다. 이 템플릿은 예제와 함께 사용되어 LLM의 출력을 일관되게 유지합니다.

**Section sources**
- [prompt.py](file://lightrag/prompt.py#L30-L100)

## DEFAULT_ENTITY_TYPES 상수의 역할
`DEFAULT_ENTITY_TYPES` 상수는 엔티티 추출 프로세스의 방향성과 범위를 결정하는 중요한 역할을 합니다. 이 상수는 `constants.py` 파일에 정의되어 있으며, 기본적으로 `["organization", "person", "geo", "event", "category"]` 값을 가집니다. `extract_entities` 함수는 `global_config["addon_params"].get("entity_types", DEFAULT_ENTITY_TYPES)`를 통해 엔티티 유형 목록을 가져옵니다. 즉, 사용자가 `.env` 파일이나 기타 설정을 통해 별도의 엔티티 유형을 지정하지 않으면, 이 기본 목록이 사용됩니다. 이는 LLM이 추출을 수행할 때 어떤 유형의 엔티티에 집중해야 하는지를 명시적으로 안내합니다. 예를 들어, `organization`과 `person`이 포함되어 있으므로, 텍스트에서 회사 이름이나 인물 이름을 식별하는 데 중점을 둡니다. 이 상수는 추출의 정확도와 관련성을 높이는 필터 역할을 하며, 불필요한 정보 추출을 방지합니다.

**Section sources**
- [constants.py](file://lightrag/constants.py#L60-L65)

## 재시도 메커니즘 분석
재시도 메커니즘은 초기 추출에서 누락된 엔티티를 보완하기 위한 중요한 기능입니다. 이 메커니즘은 `entity_extract_max_gleaning` 매개변수에 의해 제어되며, 기본값은 `DEFAULT_MAX_GLEANING` 상수인 `1`입니다. `extract_entities` 함수 내에서, 초기 추출 후 `for now_glean_index in range(entity_extract_max_gleaning):` 루프가 실행됩니다. 이 루프는 `continue_prompt`를 사용하여 LLM에 "많은 엔티티와 관계가 마지막 추출에서 놓쳤습니다. 이전 텍스트에서만 누락된 엔티티와 관계를 찾아주세요."라는 지시를 보냅니다. LLM은 이 프롬프트에 따라 새로운 추출 결과를 반환합니다. 이 결과는 `_process_extraction_result` 함수를 통해 파싱되며, 기존 결과(`maybe_nodes`, `maybe_edges`)에 새 이름의 엔티티와 관계만 추가됩니다. 루프의 마지막 단계에서는 `if_loop_prompt`를 사용하여 LLM이 추가적인 추출이 필요한지 여부를 판단하게 하며, 응답이 "yes"가 아닐 경우 루프를 종료합니다. 이 메커니즘은 추출의 포괄성을 크게 향상시킵니다.

**Section sources**
- [operate.py](file://lightrag/operate.py#L1840-L1870)

## _handle_single_entity_extraction 함수 분석
`_handle_single_entity_extraction` 함수는 LLM의 원시 출력에서 단일 엔티티를 파싱하고 정제하는 핵심 유틸리티 함수입니다. 이 함수는 `record_attributes` 리스트와 `chunk_key`를 입력으로 받습니다. 첫째, 함수는 `record_attributes`의 길이와 첫 번째 요소를 검사하여 유효한 엔티티 레코드인지 확인합니다. 이후, `entity_name`, `entity_type`, `entity_description` 각각에 대해 세 단계의 정제 과정을 거칩니다. 첫 번째 단계는 `sanitize_text_for_encoding`을 통한 엄격한 UTF-8 인코딩 정제로, 인코딩 오류를 사전에 방지합니다. 두 번째 단계는 `clean_str`을 통한 HTML 및 제어 문자 제거입니다. 세 번째 단계는 `normalize_extracted_info`를 통한 비즈니스 로직 정규화로, 중국어 문자 사이의 공백 제거 등의 작업을 수행합니다. 각 단계 후에는 유효성 검사를 수행하며, 예를 들어 엔티티 이름이 비어 있거나 무효한 유형일 경우 `None`을 반환하여 오류를 처리합니다. 성공적으로 처리된 엔티티는 딕셔너리 형태로 반환됩니다.

**Section sources**
- [operate.py](file://lightrag/operate.py#L300-L370)

## 유틸리티 함수의 데이터 품질 보장
`sanitize_text_for_encoding`과 `clean_str` 함수는 엔티티 추출 파이프라인의 데이터 품질을 보장하는 핵심 요소입니다. `sanitize_text_for_encoding` 함수는 UTF-8 인코딩 문제를 해결하기 위해 설계되었습니다. 이 함수는 대리 문자(surrogate characters)와 같은 인코딩 오류의 주요 원인을 식별하고 제거하거나 대체합니다. 또한 제어 문자를 제거하고, 텍스트가 안전하게 인코딩될 수 있도록 보장합니다. 이는 LLM API 호출 시 발생할 수 있는 `UnicodeEncodeError`를 방지합니다. 반면, `clean_str` 함수는 텍스트의 시각적 정제를 담당합니다. 이 함수는 `html.unescape`를 사용하여 HTML 이스케이프 시퀀스를 변환한 후, 정규 표현식을 사용하여 제어 문자를 제거합니다. 이 두 함수의 조합은 원시 텍스트에서 발생할 수 있는 다양한 오염 문제를 해결하여, LLM이 처리할 수 있는 깨끗하고 일관된 입력을 제공합니다. 이는 추출 결과의 정확성과 신뢰성을 높이는 데 기여합니다.

**Section sources**
- [utils.py](file://lightrag/utils.py#L1000-L1100)
- [utils.py](file://lightrag/utils.py#L800-L850)

## 실제 코드 예제를 통한 추출 과정
다음은 엔티티 추출 과정을 단계별로 보여주는 가상의 예제입니다. 입력 텍스트가 `"Alex는 Taylor와 함께 일하며, Cruz의 통제에 반대한다."`라고 가정합니다. 첫째, `extract_entities` 함수는 이 텍스트를 `entity_extract_prompt`와 결합하여 LLM에 전송합니다. LLM은 `("entity"<|>"Alex"<|>"person"<|>"Alex는 Taylor와 함께 일하며 Cruz의 통제에 반대한다.")##("entity"<|>"Taylor"<|>"person"<|>"Taylor는 Alex와 함께 일한다.")##("entity"<|>"Cruz"<|>"person"<|>"Cruz는 통제를 중시한다.")`와 같은 형식으로 응답합니다. 둘째, `_handle_single_entity_extraction` 함수는 이 출력을 파싱합니다. `record_attributes`는 `["entity", "Alex", "person", "Alex는 Taylor와 함께 일하며 Cruz의 통제에 반대한다."]`로 분할됩니다. 셋째, `sanitize_text_for_encoding`과 `clean_str`을 통해 텍스트가 정제됩니다. 넷째, `normalize_extracted_info`를 통해 엔티티 이름이 정규화됩니다. 최종적으로, `{"